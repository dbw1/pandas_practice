{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Data Formats"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "CSV - Comma Separated Values"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Importing data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "file_path =   #csv read file path\n",
      "new_file_path =     #csv write file path\n",
      "data = pd.read_csv(file_path) #reads into a dataframe\n",
      "print data['column_name']\n",
      "data['height_plus_weight'] = data['height'] + data['weight']\n",
      "data.to_csv(new_file_path) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Example from course"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas\n",
      "\n",
      "def add_full_name(path_to_csv, path_to_new_csv):\n",
      "    #Assume you will be reading in a csv file with the same columns that the\n",
      "    #Lahman baseball data set has -- most importantly, there are columns\n",
      "    #called 'nameFirst' and 'nameLast'.\n",
      "    #1) Write a function that reads a csv\n",
      "    #located at \"path_to_csv\" into a pandas dataframe and adds a new column\n",
      "    #called 'nameFull' with a player's full name.\n",
      "    #\n",
      "    #For example:\n",
      "    #   for Hank Aaron, nameFull would be 'Hank Aaron', \n",
      "\t#\n",
      "\t#2) Write the data in the pandas dataFrame to a new csv file located at\n",
      "\t#path_to_new_csv\n",
      "\n",
      "    df = pandas.read_csv(path_to_csv)\n",
      "    df['nameFull'] = df['nameFirst'] + ' ' + df['nameLast']\n",
      "    return df.to_csv(path_to_new_csv)\n",
      "\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    # For local use only\n",
      "    # If you are running this on your own machine add the path to the\n",
      "    # Lahman baseball csv and a path for the new csv.\n",
      "    # The dataset can be downloaded from this website: http://www.seanlahman.com/baseball-archive/statistics\n",
      "    # We are using the file Master.csv\n",
      "    path_to_csv = \"\"\n",
      "    path_to_new_csv = \"\"\n",
      "    add_full_name(path_to_csv, path_to_new_csv)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Relational DB query pandas/sqlite"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas\n",
      "import pandasql\n",
      "\n",
      "def select_first_50(filename):\n",
      "    # Read in our aadhaar_data csv to a pandas dataframe.  Afterwards, we rename the columns\n",
      "    # by replacing spaces with underscores and setting all characters to lowercase, so the\n",
      "    # column names more closely resemble columns names one might find in a table.\n",
      "    aadhaar_data = pandas.read_csv(filename)\n",
      "    aadhaar_data.rename(columns = lambda x: x.replace(' ', '_').lower(), inplace=True)\n",
      "\n",
      "    # Select out the first 50 values for \"registrar\" and \"enrolment_agency\"\n",
      "    # in the aadhaar_data table using SQL syntax. \n",
      "    #\n",
      "    # Note that \"enrolment_agency\" is spelled with one l. Also, the order\n",
      "    # of the select does matter. Make sure you select registrar then enrolment agency\n",
      "    # in your query.\n",
      "    #\n",
      "    # You can download a copy of the aadhaar data that we are passing \n",
      "    # into this exercise below:\n",
      "    # https://s3.amazonaws.com/content.udacity-data.com/courses/ud359/aadhaar_data.csv\n",
      "    q = \"\"\"\n",
      "        SELECT registrar, enrolment_agency\n",
      "        FROM aadhaar_data\n",
      "        LIMIT 50\n",
      "    \"\"\"\n",
      "\n",
      "    #Execute your SQL command against the pandas frame\n",
      "    aadhaar_solution = pandasql.sqldf(q.lower(), locals())\n",
      "    return aadhaar_solution    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas\n",
      "import pandasql\n",
      "\n",
      "def aggregate_query(filename):\n",
      "    # Read in our aadhaar_data csv to a pandas dataframe.  Afterwards, we rename the columns\n",
      "    # by replacing spaces with underscores and setting all characters to lowercase, so the\n",
      "    # column names more closely resemble columns names one might find in a table.\n",
      "    \n",
      "    aadhaar_data = pandas.read_csv(filename)\n",
      "    aadhaar_data.rename(columns = lambda x: x.replace(' ', '_').lower(), inplace=True)\n",
      "\n",
      "    # Write a query that will select from the aadhaar_data table how many men and how \n",
      "    # many women over the age of 50 have had aadhaar generated for them in each district.\n",
      "    # aadhaar_generated is a column in the Aadhaar Data that denotes the number who have had\n",
      "    # aadhaar generated in each row of the table.\n",
      "    #\n",
      "    # Note that in this quiz, the SQL query keywords are case sensitive. \n",
      "    # For example, if you want to do a sum make sure you type 'sum' rather than 'SUM'.\n",
      "    #\n",
      "\n",
      "    # The possible columns to select from aadhaar data are:\n",
      "    #     1) registrar\n",
      "    #     2) enrolment_agency\n",
      "    #     3) state\n",
      "    #     4) district\n",
      "    #     5) sub_district\n",
      "    #     6) pin_code\n",
      "    #     7) gender\n",
      "    #     8) age\n",
      "    #     9) aadhaar_generated\n",
      "    #     10) enrolment_rejected\n",
      "    #     11) residents_providing_email,\n",
      "    #     12) residents_providing_mobile_number\n",
      "    #\n",
      "    # You can download a copy of the aadhaar data that we are passing \n",
      "    # into this exercise below:\n",
      "    # https://s3.amazonaws.com/content.udacity-data.com/courses/ud359/aadhaar_data.csv\n",
      "        \n",
      "    q = '''\n",
      "        Select gender, district, sum(aadhaar_generated) AS total_aadhaar_generated\n",
      "        FROM aadhaar_data\n",
      "        WHERE age > 50\n",
      "        GROUP BY gender, district;\n",
      "        '''\n",
      "\n",
      "    # Execute your SQL command against the pandas frame\n",
      "    aadhaar_solution = pandasql.sqldf(q.lower(), locals())\n",
      "    return aadhaar_solution    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "API's"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Method to access JSON via API"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "import requests\n",
      "\n",
      "if __name__==\"__main__\":\n",
      "    url = url_to_api\n",
      "    data = requests.get(url).text\n",
      "    data = json.loads(data) #assumes json, returns python dict\n",
      "    print type(data)\n",
      "    print data\n",
      "    data['artist']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Dealing with Missing Values"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "listwise deletion - delete a sample from the entire list\n",
      "pairwise deletion - delete use of a sample if not relevant to certain parameter analysis, but not when relevant to others\n",
      "   ie. can't use a living person's info if counting average age of death of people in a dataset\n",
      "       BUT can use a living person's info when calculating average height."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Imputing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "replacing missing data with averages, zeros, etc.\n",
      "http://pandas.pydata.org/pandas-docs/stable/missing_data.html"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "perform linear regression using data that we have"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas\n",
      "import numpy\n",
      "\n",
      "def imputation(filename):\n",
      "    # Pandas dataframes have a method called 'fillna(value)', such that you can\n",
      "    # pass in a single value to replace any NAs in a dataframe or series. You\n",
      "    # can call it like this: \n",
      "    #     dataframe['column'] = dataframe['column'].fillna(value)\n",
      "    #\n",
      "    # Using the numpy.mean function, which calculates the mean of a numpy\n",
      "    # array, impute any missing values in our Lahman baseball\n",
      "    # data sets 'weight' column by setting them equal to the average weight.\n",
      "    # \n",
      "    # You can access the 'weight' colum in the baseball data frame by\n",
      "    # calling baseball['weight']\n",
      "\n",
      "    baseball = pandas.read_csv(filename)\n",
      "    avg_weight = numpy.mean(baseball['weight'])\n",
      "    baseball['weight'] = baseball['weight'].fillna(avg_weight)\n",
      "    #YOUR CODE GOES HERE\n",
      "\n",
      "    return baseball"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Practice with data munging"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv, sys\n",
      "import os\n",
      "\n",
      "def fix_turnstile_data(filenames):\n",
      "    '''\n",
      "    Filenames is a list of MTA Subway turnstile text files. A link to an example\n",
      "    MTA Subway turnstile text file can be seen at the URL below:\n",
      "    http://web.mta.info/developers/data/nyct/turnstile/turnstile_110507.txt\n",
      "    \n",
      "    As you can see, there are numerous data points included in each row of the\n",
      "    a MTA Subway turnstile text file. \n",
      "\n",
      "    You want to write a function that will update each row in the text\n",
      "    file so there is only one entry per row. A few examples below:\n",
      "    A002,R051,02-00-00,05-28-11,00:00:00,REGULAR,003178521,001100739\n",
      "    A002,R051,02-00-00,05-28-11,04:00:00,REGULAR,003178541,001100746\n",
      "    A002,R051,02-00-00,05-28-11,08:00:00,REGULAR,003178559,001100775\n",
      "    \n",
      "    Write the updates to a different text file in the format of \"updated_\" + filename.\n",
      "    For example:\n",
      "        1) if you read in a text file called \"turnstile_110521.txt\"\n",
      "        2) you should write the updated data to \"updated_turnstile_110521.txt\"\n",
      "\n",
      "    The order of the fields should be preserved. Remember to read through the \n",
      "    Instructor Notes below for more details on the task. \n",
      "    \n",
      "    In addition, here is a CSV reader/writer introductory tutorial:\n",
      "    http://goo.gl/HBbvyy\n",
      "    \n",
      "    You can see a sample of the turnstile text file that's passed into this function\n",
      "    and the the corresponding updated file in the links below:\n",
      "    \n",
      "    Sample input file:\n",
      "    https://www.dropbox.com/s/mpin5zv4hgrx244/turnstile_110528.txt\n",
      "    Sample updated file:\n",
      "    https://www.dropbox.com/s/074xbgio4c39b7h/solution_turnstile_110528.txt\n",
      "    '''\n",
      "    for name in filenames:\n",
      "        read_name = name\n",
      "        write_name = read_name\n",
      "        write_name = 'updated_' + write_name\n",
      "        f_out = open(write_name, 'w')\n",
      "        writer_out = csv.writer(f_out, delimiter=\",\")\n",
      "        with open(read_name, 'rb') as f:\n",
      "            turn_file = csv.reader(f)\n",
      "            try:\n",
      "                for row in turn_file:\n",
      "                    prefix = row[:3]\n",
      "                    all_else = row[3:]\n",
      "                    for i in range(0,len(all_else), 5):\n",
      "                        writer_out.writerow(prefix+all_else[i:i+5])\n",
      "            except csv.Error as e:\n",
      "                sys.exit('file %s: %s' % (read_name, e))\n",
      "        f_out.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "import sys\n",
      "\n",
      "def create_master_turnstile_file(filenames, output_file):\n",
      "    '''\n",
      "    Write a function that takes the files in the list filenames, which all have the \n",
      "    columns 'C/A, UNIT, SCP, DATEn, TIMEn, DESCn, ENTRIESn, EXITSn', and consolidates\n",
      "    them into one file located at output_file.  There should be ONE row with the column\n",
      "    headers, located at the top of the file. The input files do not have column header\n",
      "    rows of their own.\n",
      "    \n",
      "    For example, if file_1 has:\n",
      "    line 1 ...\n",
      "    line 2 ...\n",
      "    \n",
      "    and another file, file_2 has:\n",
      "    line 3 ...\n",
      "    line 4 ...\n",
      "    line 5 ...\n",
      "    \n",
      "    We need to combine file_1 and file_2 into a master_file like below:\n",
      "     'C/A, UNIT, SCP, DATEn, TIMEn, DESCn, ENTRIESn, EXITSn'\n",
      "    line 1 ...\n",
      "    line 2 ...\n",
      "    line 3 ...\n",
      "    line 4 ...\n",
      "    line 5 ...\n",
      "    '''\n",
      "    with open(output_file, 'w') as master_file:\n",
      "        master_file.write('C/A,UNIT,SCP,DATEn,TIMEn,DESCn,ENTRIESn,EXITSn\\n')\n",
      "        for filename in filenames:\n",
      "            with open(filename, 'r') as file_read:\n",
      "                try:\n",
      "                    for row in file_read:\n",
      "                        master_file.write(row+'\\n')\n",
      "                except csv.Error as e:\n",
      "                    sys.exit('file %s: %s' % (read_name,e))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "'updated_turnstile_ex.txt'"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas\n",
      "import numpy\n",
      "\n",
      "def get_hourly_entries(df):\n",
      "    '''\n",
      "    The data in the MTA Subway Turnstile data reports on the cumulative\n",
      "    number of entries and exits per row.  Assume that you have a dataframe\n",
      "    called df that contains only the rows for a particular turnstile machine\n",
      "    (i.e., unique SCP, C/A, and UNIT).  This function should change\n",
      "    these cumulative entry numbers to a count of entries since the last reading\n",
      "    (i.e., entries since the last row in the dataframe).\n",
      "    \n",
      "    More specifically, you want to do two things:\n",
      "       1) Create a new column called ENTRIESn_hourly\n",
      "       2) Assign to the column the difference between ENTRIESn of the current row \n",
      "          and the previous row. If there is any NaN, fill/replace it with 1.\n",
      "    \n",
      "    You may find the pandas functions shift() and fillna() to be helpful in this exercise.\n",
      "    \n",
      "    Examples of what your dataframe should look like at the end of this exercise:\n",
      "    \n",
      "           C/A  UNIT       SCP     DATEn     TIMEn    DESCn  ENTRIESn    EXITSn  ENTRIESn_hourly\n",
      "    0     A002  R051  02-00-00  05-01-11  00:00:00  REGULAR   3144312   1088151                1\n",
      "    1     A002  R051  02-00-00  05-01-11  04:00:00  REGULAR   3144335   1088159               23\n",
      "    2     A002  R051  02-00-00  05-01-11  08:00:00  REGULAR   3144353   1088177               18\n",
      "    3     A002  R051  02-00-00  05-01-11  12:00:00  REGULAR   3144424   1088231               71\n",
      "    4     A002  R051  02-00-00  05-01-11  16:00:00  REGULAR   3144594   1088275              170\n",
      "    5     A002  R051  02-00-00  05-01-11  20:00:00  REGULAR   3144808   1088317              214\n",
      "    6     A002  R051  02-00-00  05-02-11  00:00:00  REGULAR   3144895   1088328               87\n",
      "    7     A002  R051  02-00-00  05-02-11  04:00:00  REGULAR   3144905   1088331               10\n",
      "    8     A002  R051  02-00-00  05-02-11  08:00:00  REGULAR   3144941   1088420               36\n",
      "    9     A002  R051  02-00-00  05-02-11  12:00:00  REGULAR   3145094   1088753              153\n",
      "    10    A002  R051  02-00-00  05-02-11  16:00:00  REGULAR   3145337   1088823              243\n",
      "    ...\n",
      "    ...\n",
      "\n",
      "    '''\n",
      "    df['ENTRIESn_hourly'] = df['ENTRIESn'] - df['ENTRIESn'].shift(1)\n",
      "    df['ENTRIESn_hourly'] = df['ENTRIESn_hourly'].fillna(1)\n",
      "    \n",
      "    return df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'writer_out' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-40-a50300719a9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mall_else\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_else\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mwriter_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mall_else\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mf_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'writer_out' is not defined"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'name' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-35-96857145a959>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mread_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwrite_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'updated_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mf_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'name' is not defined"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Generates "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a=turn_file.next()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prefix = a[:3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_else = a[3:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(0,len(all_else),5):\n",
      "    print all_else[i:i+5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['05-05-11', '08:00:00', 'REGULAR', '003149331', '001090257']\n",
        "['05-05-11', '09:04:33', 'DOOR', '003149381', '001090417']\n",
        "['05-05-11', '09:04:40', 'OPEN', '003149381', '001090417']\n",
        "['05-05-11', '09:07:37', 'DOOR', '003149381', '001090417']\n",
        "['05-05-11', '09:13:03', 'OPEN', '003149381', '001090417']\n",
        "['05-05-11', '09:17:28', 'DOOR', '003149385', '001090426']\n",
        "['05-05-11', '12:00:00', 'OPEN', '003149494', '001090579']\n",
        "['05-05-11', '16:00:00', 'DOOR', '003149805', '001090652                                   ']\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prefix+all_else"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "['A002',\n",
        " 'R051',\n",
        " '02-00-00',\n",
        " '05-05-11',\n",
        " '08:00:00',\n",
        " 'REGULAR',\n",
        " '003149331',\n",
        " '001090257',\n",
        " '05-05-11',\n",
        " '09:04:33',\n",
        " 'DOOR',\n",
        " '003149381',\n",
        " '001090417',\n",
        " '05-05-11',\n",
        " '09:04:40',\n",
        " 'OPEN',\n",
        " '003149381',\n",
        " '001090417',\n",
        " '05-05-11',\n",
        " '09:07:37',\n",
        " 'DOOR',\n",
        " '003149381',\n",
        " '001090417',\n",
        " '05-05-11',\n",
        " '09:13:03',\n",
        " 'OPEN',\n",
        " '003149381',\n",
        " '001090417',\n",
        " '05-05-11',\n",
        " '09:17:28',\n",
        " 'DOOR',\n",
        " '003149385',\n",
        " '001090426',\n",
        " '05-05-11',\n",
        " '12:00:00',\n",
        " 'OPEN',\n",
        " '003149494',\n",
        " '001090579',\n",
        " '05-05-11',\n",
        " '16:00:00',\n",
        " 'DOOR',\n",
        " '003149805',\n",
        " '001090652                                   ']"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prefix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "['A002',\n",
        " 'R051',\n",
        " '02-00-00',\n",
        " '05-05-11',\n",
        " '08:00:00',\n",
        " 'REGULAR',\n",
        " '003149331',\n",
        " '001090257',\n",
        " '05-05-11',\n",
        " '09:04:33',\n",
        " 'DOOR',\n",
        " '003149381',\n",
        " '001090417',\n",
        " '05-05-11',\n",
        " '09:04:40',\n",
        " 'OPEN',\n",
        " '003149381',\n",
        " '001090417',\n",
        " '05-05-11',\n",
        " '09:07:37',\n",
        " 'DOOR',\n",
        " '003149381',\n",
        " '001090417',\n",
        " '05-05-11',\n",
        " '09:13:03',\n",
        " 'OPEN',\n",
        " '003149381',\n",
        " '001090417',\n",
        " '05-05-11',\n",
        " '09:17:28',\n",
        " 'DOOR',\n",
        " '003149385',\n",
        " '001090426',\n",
        " '05-05-11',\n",
        " '12:00:00',\n",
        " 'OPEN',\n",
        " '003149494',\n",
        " '001090579',\n",
        " '05-05-11',\n",
        " '16:00:00',\n",
        " 'DOOR',\n",
        " '003149805',\n",
        " '001090652                                   ']"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}